{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36a35428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5be5f8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = r\"C:\\Users\\arpit\\Desktop\\SAP-internal-face-mask-detection\\Medical mask\\Medical mask\\Medical Mask\\annotations\"\n",
    "image_directory = r\"C:\\Users\\arpit\\Desktop\\SAP-internal-face-mask-detection\\Medical mask\\Medical mask\\Medical Mask\\images\"\n",
    "df = pd.read_csv(r\"C:\\Users\\arpit\\Desktop\\SAP-internal-face-mask-detection\\Medical mask\\train.csv\")\n",
    "df_test = pd.read_csv(r\"C:\\Users\\arpit\\Desktop\\SAP-internal-face-mask-detection\\Medical mask\\submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "062adaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cvNet = cv2.dnn.readNetFromCaffe(prototxt=\"models/deploy.prototxt\",\n",
    "                                            caffeModel=\"models/res10_300x300_ssd_iter_140000_fp16.caffemodel\")\n",
    "def getJSON(filePathandName):\n",
    "    with open(filePathandName,'r') as f:\n",
    "        return json.load(f)\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255 for i in np.arange(0, 256)])\n",
    "    return cv2.LUT(image.astype(np.uint8), table.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>classname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2756.png</td>\n",
       "      <td>69</td>\n",
       "      <td>126</td>\n",
       "      <td>294</td>\n",
       "      <td>392</td>\n",
       "      <td>face_with_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2756.png</td>\n",
       "      <td>505</td>\n",
       "      <td>10</td>\n",
       "      <td>723</td>\n",
       "      <td>283</td>\n",
       "      <td>face_with_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2756.png</td>\n",
       "      <td>75</td>\n",
       "      <td>252</td>\n",
       "      <td>264</td>\n",
       "      <td>390</td>\n",
       "      <td>mask_colorful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2756.png</td>\n",
       "      <td>521</td>\n",
       "      <td>136</td>\n",
       "      <td>711</td>\n",
       "      <td>277</td>\n",
       "      <td>mask_colorful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6098.jpg</td>\n",
       "      <td>360</td>\n",
       "      <td>85</td>\n",
       "      <td>728</td>\n",
       "      <td>653</td>\n",
       "      <td>face_no_mask</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name   x1   x2   y1   y2       classname\n",
       "0  2756.png   69  126  294  392  face_with_mask\n",
       "1  2756.png  505   10  723  283  face_with_mask\n",
       "2  2756.png   75  252  264  390   mask_colorful\n",
       "3  2756.png  521  136  711  277   mask_colorful\n",
       "4  6098.jpg  360   85  728  653    face_no_mask"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf4382ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FileName': '1801.jpg',\n",
       " 'NumOfAnno': 1,\n",
       " 'Annotations': [{'isProtected': False,\n",
       "   'ID': 924868908868875136,\n",
       "   'BoundingBox': [451, 186, 895, 697],\n",
       "   'classname': 'face_no_mask',\n",
       "   'Confidence': 1,\n",
       "   'Attributes': {}}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonfiles= []\n",
    "for i in os.listdir(directory):\n",
    "    jsonfiles.append(getJSON(os.path.join(directory,i)))\n",
    "jsonfiles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86583218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Empty image after cropping for 5392.jpg\n",
      "Bounding Box Coordinates: 764, 138, 794, 169\n",
      "Error: Empty image after cropping for 4287.png\n",
      "Bounding Box Coordinates: 717, 118, 762, 180\n",
      "Error: Empty image after cropping for 4287.png\n",
      "Bounding Box Coordinates: 718, 150, 754, 175\n",
      "Error: Empty image after cropping for 4070.png\n",
      "Bounding Box Coordinates: 768, 287, 845, 396\n",
      "Error: Empty image after cropping for 4070.png\n",
      "Bounding Box Coordinates: 806, 306, 954, 462\n",
      "Error: Empty image after cropping for 4070.png\n",
      "Bounding Box Coordinates: 774, 346, 828, 396\n",
      "Error: Empty image after cropping for 4070.png\n",
      "Bounding Box Coordinates: 808, 380, 916, 457\n",
      "Error: Empty image after cropping for 3673.png\n",
      "Bounding Box Coordinates: 860, 173, 915, 252\n",
      "Error: Empty image after cropping for 3673.png\n",
      "Bounding Box Coordinates: 863, 210, 910, 249\n",
      "Error: Empty image after cropping for 3673.png\n",
      "Bounding Box Coordinates: 715, 170, 770, 232\n",
      "Error: Empty image after cropping for 3673.png\n",
      "Bounding Box Coordinates: 721, 209, 757, 231\n",
      "Error: Empty image after cropping for 3673.png\n",
      "Bounding Box Coordinates: 905, 135, 967, 201\n",
      "Error: Empty image after cropping for 3673.png\n",
      "Bounding Box Coordinates: 914, 176, 949, 199\n",
      "Error: Empty image after cropping for 4650.png\n",
      "Bounding Box Coordinates: 1657, 3208, 2015, 3625\n",
      "Error: Empty image after cropping for 4650.png\n",
      "Bounding Box Coordinates: 1729, 3463, 1971, 3611\n",
      "Error: Empty image after cropping for 4650.png\n",
      "Bounding Box Coordinates: 666, 68, 810, 224\n",
      "Error: Empty image after cropping for 3939.png\n",
      "Bounding Box Coordinates: 166, 378, 328, 597\n",
      "Error: Empty image after cropping for 3939.png\n",
      "Bounding Box Coordinates: 422, 455, 609, 730\n",
      "Error: Empty image after cropping for 3939.png\n",
      "Bounding Box Coordinates: 921, 214, 994, 276\n",
      "Error: Empty image after cropping for 3939.png\n",
      "Bounding Box Coordinates: 266, 388, 361, 516\n",
      "Error: Empty image after cropping for 4394.png\n",
      "Bounding Box Coordinates: 494, 32, 561, 120\n",
      "Error: Empty image after cropping for 4394.png\n",
      "Bounding Box Coordinates: 773, 48, 824, 124\n",
      "Error: Empty image after cropping for 4394.png\n",
      "Bounding Box Coordinates: 496, 84, 542, 117\n",
      "Error: Empty image after cropping for 4394.png\n",
      "Bounding Box Coordinates: 637, 150, 687, 184\n",
      "Error: Empty image after cropping for 4394.png\n",
      "Bounding Box Coordinates: 594, 121, 631, 159\n",
      "Error: Empty image after cropping for 4394.png\n",
      "Bounding Box Coordinates: 621, 106, 692, 185\n",
      "Error: Empty image after cropping for 4394.png\n",
      "Bounding Box Coordinates: 588, 89, 645, 156\n",
      "Error: Empty image after cropping for 4356.png\n",
      "Bounding Box Coordinates: 2400, 226, 2915, 899\n",
      "Error: Empty image after cropping for 4997.jpg\n",
      "Bounding Box Coordinates: 1330, 627, 1610, 955\n",
      "Error: Empty image after cropping for 4997.jpg\n",
      "Bounding Box Coordinates: 886, 649, 1111, 928\n",
      "Error: Empty image after cropping for 4997.jpg\n",
      "Bounding Box Coordinates: 442, 484, 716, 864\n",
      "Error: Empty image after cropping for 4997.jpg\n",
      "Bounding Box Coordinates: 1601, 314, 1791, 542\n",
      "Error: Empty image after cropping for 4997.jpg\n",
      "Bounding Box Coordinates: 1076, 196, 1246, 432\n",
      "Error: Empty image after cropping for 4997.jpg\n",
      "Bounding Box Coordinates: 1918, 321, 2109, 594\n",
      "Error: Empty image after cropping for 4997.jpg\n",
      "Bounding Box Coordinates: 1911, 444, 2112, 593\n",
      "Error: Empty image after cropping for 4997.jpg\n",
      "Bounding Box Coordinates: 1603, 390, 1781, 546\n",
      "Error: Empty image after cropping for 4997.jpg\n",
      "Bounding Box Coordinates: 1081, 282, 1224, 412\n",
      "Error: Empty image after cropping for 4997.jpg\n",
      "Bounding Box Coordinates: 444, 669, 700, 861\n",
      "Error: Empty image after cropping for 4997.jpg\n",
      "Bounding Box Coordinates: 877, 775, 1087, 935\n",
      "Error: Empty image after cropping for 4997.jpg\n",
      "Bounding Box Coordinates: 1342, 775, 1578, 943\n",
      "Error: Empty image after cropping for 4997.jpg\n",
      "Bounding Box Coordinates: 1351, 376, 1542, 605\n",
      "Error: Empty image after cropping for 4997.jpg\n",
      "Bounding Box Coordinates: 1342, 484, 1520, 609\n",
      "Error: Empty image after cropping for 2732.png\n",
      "Bounding Box Coordinates: 940, 196, 1100, 357\n",
      "Error: Empty image after cropping for 3160.png\n",
      "Bounding Box Coordinates: 688, 1667, 2113, 3113\n",
      "Error: Empty image after cropping for 3160.png\n",
      "Bounding Box Coordinates: 1041, 2042, 2007, 2986\n",
      "Error: Empty image after cropping for 4221.png\n",
      "Bounding Box Coordinates: 805, 124, 1079, 542\n",
      "Error: Empty image after cropping for 4221.png\n",
      "Bounding Box Coordinates: 1030, 30, 1726, 969\n",
      "Error: Empty image after cropping for 4221.png\n",
      "Bounding Box Coordinates: 1057, 473, 1599, 962\n",
      "Error: Empty image after cropping for 4221.png\n",
      "Bounding Box Coordinates: 790, 315, 1021, 526\n",
      "Error: Empty image after cropping for 4221.png\n",
      "Bounding Box Coordinates: 2004, 541, 2111, 661\n",
      "Error: Empty image after cropping for 4221.png\n",
      "Bounding Box Coordinates: 2011, 430, 2124, 661\n",
      "Error: Empty image after cropping for 4019.png\n",
      "Bounding Box Coordinates: 455, 78, 492, 118\n",
      "Error: Empty image after cropping for 4019.png\n",
      "Bounding Box Coordinates: 461, 94, 485, 115\n",
      "Error: Empty image after cropping for 4538.png\n",
      "Bounding Box Coordinates: 750, 67, 1254, 668\n",
      "Error: Empty image after cropping for 3369.png\n",
      "Bounding Box Coordinates: 557, 106, 697, 266\n",
      "Error: Empty image after cropping for 3369.png\n",
      "Bounding Box Coordinates: 553, 192, 623, 262\n",
      "Error: Empty image after cropping for 3369.png\n",
      "Bounding Box Coordinates: 696, 168, 763, 262\n",
      "Error: Empty image after cropping for 3369.png\n",
      "Bounding Box Coordinates: 551, 265, 744, 406\n",
      "Error: Empty image after cropping for 3369.png\n",
      "Bounding Box Coordinates: 584, 462, 1279, 997\n",
      "Error: Empty image after cropping for 5725.jpg\n",
      "Bounding Box Coordinates: 1339, 1131, 1813, 1710\n",
      "Error: Empty image after cropping for 5725.jpg\n",
      "Bounding Box Coordinates: 1872, 949, 2311, 1534\n",
      "Error: Empty image after cropping for 5725.jpg\n",
      "Bounding Box Coordinates: 3181, 612, 3862, 1534\n",
      "Error: Empty image after cropping for 4674.png\n",
      "Bounding Box Coordinates: 765, 150, 847, 255\n",
      "Error: Empty image after cropping for 4674.png\n",
      "Bounding Box Coordinates: 773, 216, 838, 255\n",
      "Error: Empty image after cropping for 1964.png\n",
      "Bounding Box Coordinates: 532, 335, 627, 426\n",
      "Error: Empty image after cropping for 1964.png\n",
      "Bounding Box Coordinates: 531, 384, 576, 426\n",
      "Error: Empty image after cropping for 1964.png\n",
      "Bounding Box Coordinates: 687, 384, 724, 420\n",
      "Error: Empty image after cropping for 1964.png\n",
      "Bounding Box Coordinates: 680, 340, 759, 427\n",
      "Error: Empty image after cropping for 3166.png\n",
      "Bounding Box Coordinates: 572, 97, 658, 213\n",
      "Error: Empty image after cropping for 3166.png\n",
      "Bounding Box Coordinates: 574, 157, 645, 210\n",
      "Error: Empty image after cropping for 3166.png\n",
      "Bounding Box Coordinates: 618, 153, 830, 401\n",
      "Error: Empty image after cropping for 3166.png\n",
      "Bounding Box Coordinates: 647, 269, 809, 377\n",
      "Error: Empty image after cropping for 2492.png\n",
      "Bounding Box Coordinates: 907, 321, 1095, 506\n",
      "Error: Empty image after cropping for 2492.png\n",
      "Bounding Box Coordinates: 902, 175, 1171, 506\n",
      "Error: Empty image after cropping for 2492.png\n",
      "Bounding Box Coordinates: 555, 78, 795, 386\n",
      "Error: Empty image after cropping for 2492.png\n",
      "Bounding Box Coordinates: 565, 193, 777, 355\n",
      "Error: Empty image after cropping for 2492.png\n",
      "Bounding Box Coordinates: 884, 241, 1078, 468\n",
      "Error: Empty image after cropping for 2492.png\n",
      "Bounding Box Coordinates: 885, 336, 1032, 449\n",
      "Error: Empty image after cropping for 2492.png\n",
      "Bounding Box Coordinates: 682, 523, 922, 797\n",
      "Error: Empty image after cropping for 2492.png\n",
      "Bounding Box Coordinates: 1053, 557, 1295, 846\n",
      "Error: Empty image after cropping for 2492.png\n",
      "Bounding Box Coordinates: 1390, 568, 1574, 812\n",
      "Error: Empty image after cropping for 2492.png\n",
      "Bounding Box Coordinates: 1690, 561, 1896, 816\n",
      "Error: Empty image after cropping for 2492.png\n",
      "Bounding Box Coordinates: 1968, 561, 2196, 778\n",
      "Error: Empty image after cropping for 2492.png\n",
      "Bounding Box Coordinates: 2320, 613, 2526, 861\n",
      "Error: Empty image after cropping for 2492.png\n",
      "Bounding Box Coordinates: 2680, 478, 2893, 748\n",
      "Error: Empty image after cropping for 2492.png\n",
      "Bounding Box Coordinates: 487, 98, 515, 132\n",
      "Error: Empty image after cropping for 2388.png\n",
      "Bounding Box Coordinates: 195, 502, 823, 1080\n",
      "Error: Empty image after cropping for 3082.png\n",
      "Bounding Box Coordinates: 2232, 567, 3864, 2699\n",
      "Error: Empty image after cropping for 3082.png\n",
      "Bounding Box Coordinates: 776, 757, 1871, 2225\n",
      "Error: Empty image after cropping for 5119.png\n",
      "Bounding Box Coordinates: 538, 46, 566, 93\n"
     ]
    }
   ],
   "source": [
    "jsonfiles = []\n",
    "for i in df['name'].unique():\n",
    "    f = i + \".json\"\n",
    "    jsonfiles.append(getJSON(os.path.join(directory, f)))\n",
    "\n",
    "data = []\n",
    "img_size = 124\n",
    "mask_classes = ['face_with_mask', 'mask_surgical', 'mask_colorful']\n",
    "non_mask_classes = [\"face_no_mask\"]\n",
    "labels = {'face_with_mask': 0, 'face_without_mask': 1}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    annotations = jsonfiles[index].get(\"Annotations\")\n",
    "    for annotation in annotations:\n",
    "        if annotation[\"classname\"] in mask_classes or annotation[\"classname\"] in non_mask_classes:\n",
    "            # Ensure the bounding box coordinates are valid\n",
    "            if len(annotation[\"BoundingBox\"]) == 4:\n",
    "                x, y, w, h = annotation[\"BoundingBox\"]\n",
    "                img = cv2.imread(os.path.join(image_directory, row[\"name\"]), 1)\n",
    "\n",
    "                # Check if the image is not empty\n",
    "                if img is not None:\n",
    "                    img = img[y:h, x:w]\n",
    "\n",
    "                    # Additional check for empty image after cropping\n",
    "                    if not np.all(np.isnan(img)):\n",
    "                        img = cv2.resize(img, (img_size, img_size))\n",
    "                        if annotation[\"classname\"] in mask_classes:\n",
    "                            data.append([img, labels['face_with_mask']])\n",
    "                        elif annotation[\"classname\"] in non_mask_classes:\n",
    "                            data.append([img, labels['face_without_mask']])\n",
    "                    else:\n",
    "                        print(f\"Error: Empty image after cropping for {row['name']}\")\n",
    "                        print(f\"Bounding Box Coordinates: {x}, {y}, {w}, {h}\")\n",
    "            else:\n",
    "                print(f\"Error: Invalid bounding box coordinates for {row['name']}\")\n",
    "                print(f\"Bounding Box Coordinates: {annotation['BoundingBox']}\")\n",
    "\n",
    "random.shuffle(data)\n",
    "\n",
    "p = []\n",
    "for face in data:\n",
    "    if face[1] == labels['face_with_mask']:\n",
    "        p.append(\"Mask\")\n",
    "    else:\n",
    "        p.append(\"No Mask\")\n",
    "\n",
    "# Create a count plot using Seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x=p, palette=\"Set1\")\n",
    "plt.title(\"Mask vs No Mask\")\n",
    "plt.xlabel(\"Category\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "p = []\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for features, label in data:\n",
    "    X.append(features)\n",
    "    Y.append(label)\n",
    "\n",
    "X = np.array(X) / 255.0\n",
    "X = X.reshape(-1, 124, 124, 3)\n",
    "Y = np.array(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bab39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "for features, label in data:\n",
    "    X.append(features)\n",
    "    Y.append(label)\n",
    "\n",
    "X = np.array(X) / 255.0\n",
    "X = X.reshape(-1, 124, 124, 3)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3b88fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are GPUs available\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")\n",
    "\n",
    "# Check which GPU is being used (if any)\n",
    "print(\"Available GPUs:\")\n",
    "for device in tf.config.experimental.list_physical_devices('GPU'):\n",
    "    print(device.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbce9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\", activation='relu', input_shape=(124, 124, 3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "xtrain, xval, ytrain, yval = train_test_split(X, Y, train_size=0.8, random_state=0)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False\n",
    ")\n",
    "\n",
    "datagen.fit(xtrain)\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(xtrain, ytrain, batch_size=32),\n",
    "    steps_per_epoch=xtrain.shape[0] // 32,\n",
    "    epochs=25,\n",
    "    verbose=1,\n",
    "    validation_data=(xval, yval)\n",
    ")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0093e3f",
   "metadata": {},
   "source": [
    "model.save(\"my_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"model.save(\"my_model.h5\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699b6a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### To load a saved model, you can use the following code\n",
    "loaded_model = tf.keras.models.load_model(\"my_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d99f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_images = 6  # Change this to the number of random image names you want to select\n",
    "test_images = df['name'].sample(n=num_test_images, random_state=42).tolist()\n",
    "\n",
    "gamma = 2.2 # the gamma value for adjusting image brightness\n",
    "conf_threshold = 0.2  # the confidence threshold\n",
    "nms_threshold = 0.9  # the NMS threshold\n",
    "\n",
    "fig = plt.figure(figsize=(14, 14))\n",
    "rows = 3\n",
    "cols = 2\n",
    "axes = []\n",
    "assign = {'0': 'Mask', '1': \"No Mask\"}\n",
    "\n",
    "for j, im in enumerate(test_images):\n",
    "    image = cv2.imread(os.path.join(image_directory, im), 1)\n",
    "    \n",
    "    # Adjust gamma for better visibility\n",
    "    image = adjust_gamma(image, gamma=gamma)\n",
    "    \n",
    "    (h, w) = image.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(image, (256, 192)), 1.0, (124, 124), (104.0, 177.0, 123.0))\n",
    "    cvNet.setInput(blob)\n",
    "    detections = cvNet.forward()\n",
    "\n",
    "    # Use NMS to filter out overlapping and low-confidence bounding boxes\n",
    "    indices = cv2.dnn.NMSBoxes(detections[0, 0, :, :4], detections[0, 0, :, 2], conf_threshold, nms_threshold)\n",
    "\n",
    "    for i in range(len(indices)):\n",
    "        index = indices[i]  # Get the index from indices\n",
    "        box = detections[0, 0, index, 3:7] * np.array([w, h, w, h])\n",
    "        confidence = detections[0, 0, index, 2]\n",
    "\n",
    "        # Check if confidence is above threshold and box coordinates are valid\n",
    "        if confidence > conf_threshold:\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "            frame = image[startY:endY, startX:endX]\n",
    "\n",
    "            im = cv2.resize(frame, (img_size, img_size))\n",
    "            im = np.array(im) / 255.0\n",
    "            im = im.reshape(1, 124, 124, 3)\n",
    "\n",
    "            try:\n",
    "                result = model.predict(im)\n",
    "            except:\n",
    "                result = loaded_model.predict(im)\n",
    "\n",
    "            if result >= 0.5:\n",
    "                label_Y = 1\n",
    "            else:\n",
    "                label_Y = 0\n",
    "\n",
    "            cv2.rectangle(image, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
    "            cv2.putText(image, assign[str(label_Y)], (startX, startY - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.5, (36, 255, 12), 2)\n",
    "\n",
    "    axes.append(fig.add_subplot(rows, cols, j + 1))\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pretrained_model(model, image_directory, df_test, img_size=124, gamma=2.0, conf_threshold=0.2, nms_threshold=0.1, prediction_threshold=0.5, num_test_images=6):\n",
    "    correct_predictions = 0\n",
    "    total_images = len(df_test)\n",
    "\n",
    "    # Assuming 'df' contains the necessary information\n",
    "    # Replace this with your actual column names if they are different\n",
    "    X = df[['name', 'x1', 'x2', 'y1', 'y2', 'classname']]\n",
    "    Y = df['label']  # Replace 'label' with your actual column name for class labels\n",
    "\n",
    "    # Split the data into training and validation sets\n",
    "    xtrain, xval, ytrain, yval = train_test_split(X, Y, train_size=0.8, random_state=0)\n",
    "\n",
    "    # Take a random subset of validation data for testing\n",
    "    random_subset_indices = random.sample(range(len(xval)), num_test_images)\n",
    "    xtest_subset = xval.iloc[random_subset_indices]\n",
    "    ytest_subset = yval.iloc[random_subset_indices]\n",
    "\n",
    "    for index, row in xtest_subset.iterrows():\n",
    "        im = row['name']\n",
    "        ground_truth_label = ytest_subset.loc[index]\n",
    "\n",
    "        # Load the image\n",
    "        image_path = os.path.join(image_directory, im)\n",
    "        image = cv2.imread(image_path, 1)\n",
    "\n",
    "        if image is None:\n",
    "            print(f\"Error loading image: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        # Adjust gamma for better visibility\n",
    "        image = adjust_gamma(image, gamma=gamma)\n",
    "\n",
    "        (h, w) = image.shape[:2]\n",
    "        # Use the same dimensions for detection and resizing\n",
    "        blob = cv2.dnn.blobFromImage(image, 1.0, (img_size, img_size), (104.0, 177.0, 123.0))\n",
    "        cvNet.setInput(blob)\n",
    "        detections = cvNet.forward()\n",
    "\n",
    "        # Use NMS to filter out overlapping and low-confidence bounding boxes\n",
    "        indices = cv2.dnn.NMSBoxes(detections[0, 0, :, :4], detections[0, 0, :, 2], conf_threshold, nms_threshold)\n",
    "\n",
    "        if len(indices) > 0:\n",
    "            index = indices[0]  # Get the first index from indices\n",
    "            box = detections[0, 0, index, 3:7] * np.array([w, h, w, h])\n",
    "            confidence = detections[0, 0, index, 2]\n",
    "\n",
    "            # Check if confidence is above threshold and box coordinates are valid\n",
    "            if confidence > conf_threshold:\n",
    "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "                # Check if the bounding box coordinates are valid\n",
    "                if startX < endX and startY < endY:\n",
    "                    frame = image[startY:endY, startX:endX]\n",
    "\n",
    "                    # Check if the frame is not empty\n",
    "                    if frame.size == 0:\n",
    "                        print(f\"Error: Empty frame for image {im}\")\n",
    "                        continue\n",
    "\n",
    "                    im = cv2.resize(frame, (img_size, img_size))\n",
    "                    im = np.array(im) / 255.0\n",
    "                    im = im.reshape(1, img_size, img_size, 3)\n",
    "\n",
    "                    try:\n",
    "                        result = model.predict(im)\n",
    "                    except:\n",
    "                        result = model.predict(im)\n",
    "\n",
    "                    if result >= prediction_threshold:\n",
    "                        label_Y = 1\n",
    "                    else:\n",
    "                        label_Y = 0\n",
    "\n",
    "                    # Check if the predicted label matches the ground truth\n",
    "                    if label_Y == labels[ground_truth_label]:\n",
    "                        correct_predictions += 1\n",
    "                    else:\n",
    "                        print(f\"Mismatch: Predicted {label_Y}, Ground Truth {labels[ground_truth_label]} for image {im}\")\n",
    "\n",
    "    accuracy = correct_predictions / num_test_images\n",
    "    return accuracy\n",
    "\n",
    "# Test the pre-trained model and get accuracy\n",
    "accuracy = test_pretrained_model(loaded_model, image_directory, df_test)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['classname'] = df['classname'].apply(lambda x: 'face_with_mask' if x in ['face_with_mask', 'mask_surgical', 'mask_colorful'] else 'face_without_mask')\n",
    "\n",
    "# Verify the unique values in the 'classname' column after conversion\n",
    "print(df['classname'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
