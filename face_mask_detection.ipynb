{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS AND CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.applications import Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n",
      "Available GPUs:\n",
      "/physical_device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# Check if there are GPUs available\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")\n",
    "\n",
    "# Check which GPU is being used (if any)\n",
    "print(\"Available GPUs:\")\n",
    "for device in tf.config.experimental.list_physical_devices('GPU'):\n",
    "    print(device.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USING PRE-TRAINED MODEL(YOLOV8L-face) FOR FACE-DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "yolo_weights='yolov8l-face.pt'\n",
    "yolomodel=YOLO(yolo_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if YOLOv8l-face is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\arpit\\Desktop\\SAP-internal-face-mask-detection\\DETECTION_IMAGES\\images\\maksssksksss3.png: 448x640 11 faces, 199.0ms\n",
      "Speed: 12.7ms preprocess, 199.0ms inference, 13.0ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    }
   ],
   "source": [
    "image_path = r'C:\\Users\\arpit\\Desktop\\SAP-internal-face-mask-detection\\DETECTION_IMAGES\\images\\maksssksksss3.png'\n",
    "results=yolomodel(image_path)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the bounding box coordinates\n",
    "boxes = results.boxes.xyxy if hasattr(results.boxes, 'xyxy') else None\n",
    "\n",
    "image = cv2.imread(results.path)\n",
    "if boxes is not None:\n",
    "    for box in boxes:\n",
    "        x, y, x_max, y_max = map(int, box)\n",
    "\n",
    "        color = (0, 255, 0) \n",
    "        cv2.rectangle(image, (x, y), (x_max, y_max), color, 2)\n",
    "\n",
    "    cv2.imshow('Object Detection', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"No bounding box information found in the result.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSFER LEARNING FOR FACE-MASK-DETECTION USING Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Flatten, Dense,Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.metrics import Precision,Recall,AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load train and test set\n",
    "train_dir = r'C:\\Users\\arpit\\Desktop\\SAP-internal-face-mask-detection\\Face Mask Dataset\\Train'\n",
    "test_dir = r'C:\\Users\\arpit\\Desktop\\SAP-internal-face-mask-detection\\Face Mask Dataset\\Test'\n",
    "val_dir = r'C:\\Users\\arpit\\Desktop\\SAP-internal-face-mask-detection\\Face Mask Dataset\\Validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "Batch_size=32\n",
    "learning_rate=1e-4\n",
    "Epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Data Argumentaors\n",
    "train_datagen=ImageDataGenerator(\n",
    "        rescale=1 / 255.0,\n",
    "        rotation_range=20,\n",
    "        zoom_range=0.2,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        shear_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=0.20)\n",
    "test_val_datagen=ImageDataGenerator(\n",
    "    rescale=1.0/255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=train_dir,\n",
    "    target_size=(128,128),\n",
    "    class_mode='categorical',\n",
    "    batch_size=Batch_size\n",
    "    )\n",
    "val_generator = test_val_datagen.flow_from_directory(\n",
    "    directory=val_dir,\n",
    "    target_size=(128,128),\n",
    "    class_mode='categorical',\n",
    "    batch_size=Batch_size\n",
    "    )\n",
    "\n",
    "test_generator = test_val_datagen.flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    target_size=(128,128),\n",
    "    class_mode='categorical',\n",
    "    batch_size=Batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xception_model = Xception(weights='imagenet',include_top=False,input_shape=(128,128,3))\n",
    "\n",
    "for layer in Xception_model.layers[:-5]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model = Sequential()\n",
    "model.add(Xception_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=['accuracy', Precision(), Recall(), AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                    validation_data=val_generator,\n",
    "                    steps_per_epoch=train_generator.samples // Batch_size,   \n",
    "                    validation_steps=val_generator.samples // Batch_size,\n",
    "                    epochs=Epochs,  \n",
    "                    verbose=2,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(history.history)\n",
    "df.to_csv('face-mask.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('face_mask2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATION AND PREDICTION  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('face-mask.csv')\n",
    "\n",
    "# Create a figure with multiple subplots\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 10))\n",
    "\n",
    "# training and validation loss\n",
    "axes[0, 0].plot(df['loss'], label='Training Loss')\n",
    "axes[0, 0].plot(df['val_loss'], label='Validation Loss')\n",
    "axes[0, 0].set_title('Training and Validation Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "#  training and validation accuracy\n",
    "axes[0, 1].plot(df['accuracy'], label='Training Accuracy')\n",
    "axes[0, 1].plot(df['val_accuracy'], label='Validation Accuracy')\n",
    "axes[0, 1].set_title('Training and Validation Accuracy')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "#training and validation precision\n",
    "axes[1, 0].plot(df['precision'], label='Training Precision')\n",
    "axes[1, 0].plot(df['val_precision'], label='Validation Precision')\n",
    "axes[1, 0].set_title('Training and Validation Precision')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Precision')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# training and validation recall\n",
    "axes[1, 1].plot(df['recall'], label='Training Recall')\n",
    "axes[1, 1].plot(df['val_recall'], label='Validation Recall')\n",
    "axes[1, 1].set_title('Training and Validation Recall')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Recall')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "0: 480x640 1 face, 128.0ms\n",
      "Speed: 3.0ms preprocess, 128.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "\n",
      "0: 480x640 1 face, 91.0ms\n",
      "Speed: 4.5ms preprocess, 91.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "\n",
      "0: 480x640 1 face, 133.3ms\n",
      "Speed: 2.0ms preprocess, 133.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "\n",
      "0: 480x640 1 face, 115.2ms\n",
      "Speed: 3.0ms preprocess, 115.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "\n",
      "0: 480x640 1 face, 116.6ms\n",
      "Speed: 3.1ms preprocess, 116.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "\n",
      "0: 480x640 1 face, 111.0ms\n",
      "Speed: 4.0ms preprocess, 111.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "\n",
      "0: 480x640 1 face, 163.9ms\n",
      "Speed: 3.0ms preprocess, 163.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "\n",
      "0: 480x640 1 face, 93.6ms\n",
      "Speed: 3.0ms preprocess, 93.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "\n",
      "0: 480x640 1 face, 99.2ms\n",
      "Speed: 3.0ms preprocess, 99.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "\n",
      "0: 480x640 1 face, 134.1ms\n",
      "Speed: 2.9ms preprocess, 134.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "\n",
      "0: 480x640 1 face, 125.1ms\n",
      "Speed: 1.9ms preprocess, 125.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "\n",
      "0: 480x640 1 face, 130.1ms\n",
      "Speed: 4.0ms preprocess, 130.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "\n",
      "0: 480x640 1 face, 151.2ms\n",
      "Speed: 3.0ms preprocess, 151.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "\n",
      "0: 480x640 1 face, 150.2ms\n",
      "Speed: 4.0ms preprocess, 150.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "\n",
      "0: 480x640 1 face, 99.4ms\n",
      "Speed: 3.0ms preprocess, 99.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "\n",
      "0: 480x640 1 face, 63.4ms\n",
      "Speed: 1.0ms preprocess, 63.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "\n",
      "0: 480x640 1 face, 60.3ms\n",
      "Speed: 1.0ms preprocess, 60.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "\n",
      "0: 480x640 1 face, 75.0ms\n",
      "Speed: 3.0ms preprocess, 75.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "\n",
      "0: 480x640 1 face, 65.1ms\n",
      "Speed: 1.0ms preprocess, 65.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "\n",
      "0: 480x640 1 face, 66.9ms\n",
      "Speed: 1.0ms preprocess, 66.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "\n",
      "0: 480x640 1 face, 71.5ms\n",
      "Speed: 1.0ms preprocess, 71.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "\n",
      "0: 480x640 1 face, 93.5ms\n",
      "Speed: 2.0ms preprocess, 93.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "\n",
      "0: 480x640 1 face, 70.2ms\n",
      "Speed: 1.0ms preprocess, 70.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "\n",
      "0: 480x640 1 face, 117.5ms\n",
      "Speed: 2.0ms preprocess, 117.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "\n",
      "0: 480x640 1 face, 78.2ms\n",
      "Speed: 2.0ms preprocess, 78.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "\n",
      "0: 480x640 1 face, 146.6ms\n",
      "Speed: 3.0ms preprocess, 146.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "\n",
      "0: 480x640 1 face, 126.9ms\n",
      "Speed: 3.0ms preprocess, 126.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "\n",
      "0: 480x640 1 face, 83.4ms\n",
      "Speed: 2.0ms preprocess, 83.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "\n",
      "0: 480x640 1 face, 139.7ms\n",
      "Speed: 2.0ms preprocess, 139.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "\n",
      "0: 480x640 1 face, 72.0ms\n",
      "Speed: 1.0ms preprocess, 72.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "\n",
      "0: 480x640 1 face, 71.5ms\n",
      "Speed: 1.0ms preprocess, 71.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "\n",
      "0: 480x640 1 face, 115.2ms\n",
      "Speed: 1.0ms preprocess, 115.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "\n",
      "0: 480x640 1 face, 62.4ms\n",
      "Speed: 2.0ms preprocess, 62.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "\n",
      "0: 480x640 1 face, 153.0ms\n",
      "Speed: 4.0ms preprocess, 153.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "\n",
      "0: 480x640 1 face, 84.8ms\n",
      "Speed: 1.0ms preprocess, 84.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "\n",
      "0: 480x640 1 face, 85.2ms\n",
      "Speed: 2.0ms preprocess, 85.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "\n",
      "0: 480x640 1 face, 71.5ms\n",
      "Speed: 1.0ms preprocess, 71.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "\n",
      "0: 480x640 1 face, 97.3ms\n",
      "Speed: 2.0ms preprocess, 97.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "\n",
      "0: 480x640 1 face, 62.0ms\n",
      "Speed: 0.9ms preprocess, 62.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "\n",
      "0: 480x640 1 face, 119.7ms\n",
      "Speed: 2.9ms preprocess, 119.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "\n",
      "0: 480x640 1 face, 146.1ms\n",
      "Speed: 3.0ms preprocess, 146.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "\n",
      "0: 480x640 1 face, 107.1ms\n",
      "Speed: 1.0ms preprocess, 107.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "\n",
      "0: 480x640 1 face, 118.2ms\n",
      "Speed: 3.0ms preprocess, 118.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "\n",
      "0: 480x640 1 face, 98.2ms\n",
      "Speed: 3.0ms preprocess, 98.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "\n",
      "0: 480x640 1 face, 60.9ms\n",
      "Speed: 1.0ms preprocess, 60.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "\n",
      "0: 480x640 1 face, 68.6ms\n",
      "Speed: 1.0ms preprocess, 68.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "\n",
      "0: 480x640 1 face, 60.9ms\n",
      "Speed: 2.0ms preprocess, 60.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "\n",
      "0: 480x640 1 face, 88.4ms\n",
      "Speed: 2.0ms preprocess, 88.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "\n",
      "0: 480x640 1 face, 139.9ms\n",
      "Speed: 2.0ms preprocess, 139.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "\n",
      "0: 480x640 1 face, 123.5ms\n",
      "Speed: 3.0ms preprocess, 123.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "\n",
      "0: 480x640 1 face, 67.4ms\n",
      "Speed: 1.0ms preprocess, 67.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "\n",
      "0: 480x640 1 face, 134.2ms\n",
      "Speed: 3.0ms preprocess, 134.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "\n",
      "0: 480x640 1 face, 97.3ms\n",
      "Speed: 2.9ms preprocess, 97.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "\n",
      "0: 480x640 1 face, 77.6ms\n",
      "Speed: 1.0ms preprocess, 77.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "\n",
      "0: 480x640 1 face, 92.1ms\n",
      "Speed: 3.0ms preprocess, 92.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "\n",
      "0: 480x640 1 face, 108.2ms\n",
      "Speed: 1.0ms preprocess, 108.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "\n",
      "0: 480x640 1 face, 132.1ms\n",
      "Speed: 3.0ms preprocess, 132.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "\n",
      "0: 480x640 1 face, 128.9ms\n",
      "Speed: 3.0ms preprocess, 128.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "\n",
      "0: 480x640 1 face, 102.6ms\n",
      "Speed: 2.5ms preprocess, 102.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "\n",
      "0: 480x640 1 face, 124.6ms\n",
      "Speed: 4.0ms preprocess, 124.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "\n",
      "0: 480x640 1 face, 132.5ms\n",
      "Speed: 3.0ms preprocess, 132.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "\n",
      "0: 480x640 1 face, 97.7ms\n",
      "Speed: 3.0ms preprocess, 97.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "\n",
      "0: 480x640 1 face, 99.2ms\n",
      "Speed: 4.0ms preprocess, 99.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "\n",
      "0: 480x640 1 face, 69.8ms\n",
      "Speed: 1.0ms preprocess, 69.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "\n",
      "0: 480x640 1 face, 64.1ms\n",
      "Speed: 2.0ms preprocess, 64.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "\n",
      "0: 480x640 1 face, 64.7ms\n",
      "Speed: 2.0ms preprocess, 64.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "\n",
      "0: 480x640 1 face, 57.2ms\n",
      "Speed: 1.0ms preprocess, 57.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "\n",
      "0: 480x640 1 face, 136.5ms\n",
      "Speed: 3.0ms preprocess, 136.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "\n",
      "0: 480x640 1 face, 64.1ms\n",
      "Speed: 2.0ms preprocess, 64.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "\n",
      "0: 480x640 1 face, 113.5ms\n",
      "Speed: 2.0ms preprocess, 113.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "\n",
      "0: 480x640 1 face, 64.4ms\n",
      "Speed: 2.0ms preprocess, 64.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "\n",
      "0: 480x640 1 face, 69.8ms\n",
      "Speed: 1.0ms preprocess, 69.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "\n",
      "0: 480x640 1 face, 89.5ms\n",
      "Speed: 2.0ms preprocess, 89.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "\n",
      "0: 480x640 1 face, 159.7ms\n",
      "Speed: 3.0ms preprocess, 159.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "\n",
      "0: 480x640 1 face, 154.7ms\n",
      "Speed: 2.0ms preprocess, 154.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "\n",
      "0: 480x640 1 face, 113.3ms\n",
      "Speed: 3.0ms preprocess, 113.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "\n",
      "0: 480x640 1 face, 101.5ms\n",
      "Speed: 2.9ms preprocess, 101.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "\n",
      "0: 480x640 1 face, 83.3ms\n",
      "Speed: 3.0ms preprocess, 83.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "\n",
      "0: 480x640 1 face, 109.7ms\n",
      "Speed: 1.9ms preprocess, 109.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "\n",
      "0: 480x640 1 face, 97.3ms\n",
      "Speed: 3.0ms preprocess, 97.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "\n",
      "0: 480x640 1 face, 144.7ms\n",
      "Speed: 2.9ms preprocess, 144.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "\n",
      "0: 480x640 1 face, 136.7ms\n",
      "Speed: 3.0ms preprocess, 136.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "\n",
      "0: 480x640 1 face, 147.8ms\n",
      "Speed: 4.0ms preprocess, 147.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "\n",
      "0: 480x640 1 face, 170.6ms\n",
      "Speed: 3.0ms preprocess, 170.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "\n",
      "0: 480x640 1 face, 129.1ms\n",
      "Speed: 3.0ms preprocess, 129.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "\n",
      "0: 480x640 1 face, 137.7ms\n",
      "Speed: 2.9ms preprocess, 137.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "\n",
      "0: 480x640 1 face, 106.2ms\n",
      "Speed: 2.9ms preprocess, 106.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "\n",
      "0: 480x640 1 face, 120.6ms\n",
      "Speed: 4.0ms preprocess, 120.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "\n",
      "0: 480x640 1 face, 104.0ms\n",
      "Speed: 3.9ms preprocess, 104.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "\n",
      "0: 480x640 1 face, 67.0ms\n",
      "Speed: 3.0ms preprocess, 67.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "\n",
      "0: 480x640 1 face, 69.7ms\n",
      "Speed: 3.0ms preprocess, 69.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "\n",
      "0: 480x640 1 face, 67.0ms\n",
      "Speed: 3.0ms preprocess, 67.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "\n",
      "0: 480x640 1 face, 115.5ms\n",
      "Speed: 2.0ms preprocess, 115.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "\n",
      "0: 480x640 1 face, 76.3ms\n",
      "Speed: 2.0ms preprocess, 76.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "\n",
      "0: 480x640 1 face, 68.0ms\n",
      "Speed: 2.0ms preprocess, 68.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "\n",
      "0: 480x640 1 face, 72.5ms\n",
      "Speed: 2.0ms preprocess, 72.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "\n",
      "0: 480x640 1 face, 64.2ms\n",
      "Speed: 2.0ms preprocess, 64.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "\n",
      "0: 480x640 1 face, 81.9ms\n",
      "Speed: 3.0ms preprocess, 81.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "\n",
      "0: 480x640 1 face, 70.2ms\n",
      "Speed: 2.0ms preprocess, 70.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "\n",
      "0: 480x640 1 face, 125.6ms\n",
      "Speed: 3.0ms preprocess, 125.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "\n",
      "0: 480x640 1 face, 73.1ms\n",
      "Speed: 1.0ms preprocess, 73.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "\n",
      "0: 480x640 1 face, 101.5ms\n",
      "Speed: 1.0ms preprocess, 101.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "\n",
      "0: 480x640 1 face, 70.6ms\n",
      "Speed: 3.0ms preprocess, 70.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "\n",
      "0: 480x640 1 face, 60.0ms\n",
      "Speed: 2.0ms preprocess, 60.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "\n",
      "0: 480x640 1 face, 93.9ms\n",
      "Speed: 2.0ms preprocess, 93.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "\n",
      "0: 480x640 1 face, 89.1ms\n",
      "Speed: 3.0ms preprocess, 89.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "\n",
      "0: 480x640 1 face, 82.6ms\n",
      "Speed: 1.0ms preprocess, 82.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "\n",
      "0: 480x640 1 face, 113.5ms\n",
      "Speed: 2.0ms preprocess, 113.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "\n",
      "0: 480x640 1 face, 105.5ms\n",
      "Speed: 2.0ms preprocess, 105.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "\n",
      "0: 480x640 1 face, 107.9ms\n",
      "Speed: 4.0ms preprocess, 107.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "\n",
      "0: 480x640 1 face, 103.0ms\n",
      "Speed: 1.9ms preprocess, 103.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "\n",
      "0: 480x640 1 face, 144.3ms\n",
      "Speed: 3.0ms preprocess, 144.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "\n",
      "0: 480x640 1 face, 83.6ms\n",
      "Speed: 2.0ms preprocess, 83.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "\n",
      "0: 480x640 1 face, 102.9ms\n",
      "Speed: 2.0ms preprocess, 102.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "\n",
      "0: 480x640 1 face, 69.1ms\n",
      "Speed: 1.3ms preprocess, 69.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "\n",
      "0: 480x640 1 face, 85.6ms\n",
      "Speed: 1.0ms preprocess, 85.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "class FaceDetection:\n",
    "    def __init__(self, capture_index,mask_model):\n",
    "        self.capture_index = capture_index\n",
    "        self.mask_model=mask_model\n",
    "        self.model = self.load_model()\n",
    "    def load_model(self):\n",
    "        model = YOLO(yolo_weights)\n",
    "        model.fuse()\n",
    "        return model\n",
    "\n",
    "    def detect(self, frame):\n",
    "        resized_frame = cv2.resize(frame, (640, 480))\n",
    "        results = self.model(resized_frame)[0]\n",
    "        return results\n",
    "\n",
    "    def plot_bboxes(self, results, frame):\n",
    "        face_roi = frame  # Initialize face_roi to the entire frame\n",
    "        x, y, x_max, y_max = 0, 0, 0, 0  # Initialize bounding box coordinates\n",
    "        for result in results.boxes.xyxy:\n",
    "            #processing individually\n",
    "            x, y, x_max, y_max = map(int, result.cpu().numpy()[:4])\n",
    "            frame = cv2.rectangle(frame, (x, y), (x_max, y_max), (0, 255, 0), 2)\n",
    "\n",
    "            face_roi = frame[y:y_max, x:x_max]\n",
    "            #resizing\n",
    "            resized_frame = cv2.resize(face_roi, (128, 128))\n",
    "            normalized_frame = resized_frame / 255.0\n",
    "            input_frame = np.expand_dims(normalized_frame, axis=0)\n",
    "            \n",
    "            # Predict using the face_mask_model\n",
    "            predictions = self.mask_model.predict(input_frame)\n",
    "            probability_with_mask = predictions[0, 0]\n",
    "\n",
    "            label = 'With Mask' if probability_with_mask >= 0.5 else 'Without Mask'\n",
    "            color = (0, 255, 0) if label == 'With Mask' else (0, 0, 255)\n",
    "\n",
    "            cv2.rectangle(frame, (x, y), (x_max, y_max), color, 2)\n",
    "            cv2.putText(frame, f'{label} ({probability_with_mask:.2f})', (x, y - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2, cv2.LINE_AA)\n",
    "        return frame\n",
    "\n",
    "    def __call__(self):\n",
    "        cap = cv2.VideoCapture(self.capture_index)\n",
    "        assert cap.isOpened()\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            results = self.detect(frame)\n",
    "            frame=self.plot_bboxes(results,frame)\n",
    "            \n",
    "            cv2.imshow('Face Mask and YOLOv8 Detection', frame)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    face_mask_model = tf.keras.models.load_model('face_mask2.h5')\n",
    "    capture_index = 0  \n",
    "    face_detector = FaceDetection(capture_index,face_mask_model)\n",
    "    face_detector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\arpit\\Desktop\\SAP-internal-face-mask-detection\\DETECTION_IMAGES\\images\\maksssksksss5.png: 448x640 5 faces, 88.9ms\n",
      "Speed: 2.9ms preprocess, 88.9ms inference, 3.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "1/1 [==============================] - 1s 685ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "image_path = r'C:\\Users\\arpit\\Desktop\\SAP-internal-face-mask-detection\\DETECTION_IMAGES\\images\\maksssksksss5.png'\n",
    "face_mask_model = tf.keras.models.load_model('face_mask2.h5')\n",
    "results=yolomodel(image_path)[0]\n",
    "boxes = results.boxes.xyxy if hasattr(results.boxes, 'xyxy') else None\n",
    "\n",
    "image = cv2.imread(results.path)\n",
    "if boxes is not None:\n",
    "    for box in boxes:\n",
    "        x, y, x_max, y_max = map(int, box)\n",
    "        color = (0, 255, 0) \n",
    "        im=cv2.rectangle(image, (x, y), (x_max, y_max), color, 2)\n",
    "        face_roi= im[y:y_max, x:x_max]\n",
    "        \n",
    "        resized_frame = cv2.resize(face_roi, (128, 128))\n",
    "        normalized_frame = resized_frame / 255.0\n",
    "        input_frame = np.expand_dims(normalized_frame, axis=0)\n",
    "        \n",
    "        # Predict using the face_mask_model\n",
    "        predictions = face_mask_model.predict(input_frame)\n",
    "        probability_with_mask = predictions[0, 0]\n",
    "\n",
    "        label = 'With Mask' if probability_with_mask >= 0.5 else 'Without Mask'\n",
    "        color = (0, 255, 0) if label == 'With Mask' else (0, 0, 255)\n",
    "\n",
    "        cv2.rectangle(im, (x, y), (x_max, y_max), color, 2)\n",
    "        cv2.putText(im, f'{label} ({probability_with_mask:.2f})', (x, y - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow('Object Detection', image)\n",
    "        \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"No bounding box information found in the result.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>val_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.094180</td>\n",
       "      <td>0.984852</td>\n",
       "      <td>0.984852</td>\n",
       "      <td>0.984852</td>\n",
       "      <td>0.995408</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.99875</td>\n",
       "      <td>0.99875</td>\n",
       "      <td>0.99875</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.024827</td>\n",
       "      <td>0.994783</td>\n",
       "      <td>0.994783</td>\n",
       "      <td>0.994783</td>\n",
       "      <td>0.998427</td>\n",
       "      <td>0.008028</td>\n",
       "      <td>0.99625</td>\n",
       "      <td>0.99625</td>\n",
       "      <td>0.99625</td>\n",
       "      <td>0.999967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015957</td>\n",
       "      <td>0.995486</td>\n",
       "      <td>0.995486</td>\n",
       "      <td>0.995486</td>\n",
       "      <td>0.999202</td>\n",
       "      <td>0.002543</td>\n",
       "      <td>0.99875</td>\n",
       "      <td>0.99875</td>\n",
       "      <td>0.99875</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.025634</td>\n",
       "      <td>0.994683</td>\n",
       "      <td>0.994683</td>\n",
       "      <td>0.994683</td>\n",
       "      <td>0.998431</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.017774</td>\n",
       "      <td>0.996087</td>\n",
       "      <td>0.996087</td>\n",
       "      <td>0.996087</td>\n",
       "      <td>0.998809</td>\n",
       "      <td>0.003736</td>\n",
       "      <td>0.99750</td>\n",
       "      <td>0.99750</td>\n",
       "      <td>0.99750</td>\n",
       "      <td>0.999994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  precision    recall       auc  val_loss  val_accuracy  \\\n",
       "0  0.094180  0.984852   0.984852  0.984852  0.995408  0.001069       0.99875   \n",
       "1  0.024827  0.994783   0.994783  0.994783  0.998427  0.008028       0.99625   \n",
       "2  0.015957  0.995486   0.995486  0.995486  0.999202  0.002543       0.99875   \n",
       "3  0.025634  0.994683   0.994683  0.994683  0.998431  0.000837       1.00000   \n",
       "4  0.017774  0.996087   0.996087  0.996087  0.998809  0.003736       0.99750   \n",
       "\n",
       "   val_precision  val_recall   val_auc  \n",
       "0        0.99875     0.99875  0.999998  \n",
       "1        0.99625     0.99625  0.999967  \n",
       "2        0.99875     0.99875  0.999999  \n",
       "3        1.00000     1.00000  1.000000  \n",
       "4        0.99750     0.99750  0.999994  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df=pd.read_csv(\"face-mask.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"face-mask.csv\")\n",
    "\n",
    "# Plot and save Training and Validation Loss\n",
    "plt.plot(df['loss'], label='Training Loss')\n",
    "plt.plot(df['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('loss_plot.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot and save Training and Validation Accuracy\n",
    "plt.plot(df['accuracy'], label='Training Accuracy')\n",
    "plt.plot(df['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_plot.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot and save Training and Validation Precision\n",
    "plt.plot(df['precision'], label='Training Precision')\n",
    "plt.plot(df['val_precision'], label='Validation Precision')\n",
    "plt.title('Training and Validation Precision')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.savefig('precision_plot.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot and save Training and Validation Recall\n",
    "plt.plot(df['recall'], label='Training Recall')\n",
    "plt.plot(df['val_recall'], label='Validation Recall')\n",
    "plt.title('Training and Validation Recall')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend()\n",
    "plt.savefig('recall_plot.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot and save Training and Validation Recall\n",
    "plt.plot(df['auc'], label='Training Recall')\n",
    "plt.plot(df['val_auc'], label='Validation Recall')\n",
    "plt.title('Training and Validation Recall')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend()\n",
    "plt.savefig('auc_plot.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
